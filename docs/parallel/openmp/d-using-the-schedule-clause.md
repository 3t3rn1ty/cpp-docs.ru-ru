---
title: "D. Using the schedule Clause | Microsoft Docs"
ms.custom: ""
ms.date: "12/05/2016"
ms.prod: "visual-studio-dev14"
ms.reviewer: ""
ms.suite: ""
ms.technology: 
  - "devlang-cpp"
ms.tgt_pltfrm: ""
ms.topic: "article"
dev_langs: 
  - "C++"
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
caps.latest.revision: 5
caps.handback.revision: 5
author: "mikeblome"
ms.author: "mblome"
manager: "ghogen"
---
# D. Using the schedule Clause
[!INCLUDE[vs2017banner](../../assembler/inline/includes/vs2017banner.md)]

Параллельная область имеет по крайней мере один барьера, в его конце, и может иметь дополнительные барьеры в ее.  На каждом барьере, другие участники команды должны ожидать последний поток для прибытия.  Чтобы свернуть это время ожидания общий работа распределяется должен быть таким образом, чтобы все потоки приедут в барьер на примерно столько же время.  Если некоторый этого общего рабочий содержится в **для** конструирования  `schedule` предложение может быть использовано для этой цели.  
  
 При повторяющихся ссылок на те же объекты, выбор расписания, a **для** конструкция может быть определена в основном характеристиками запоминающей системы, например наличие и размер кэшей, а время доступа к памяти равномерны или неединобразны.  Такие факторы может сделать его предпочтительной иметь каждый поток постоянно относиться к одному и тому же набору элементов массива в ряду циклов, даже если некоторые потоки присвоено относительно меньше работы в некоторых циклов.  Это делается с помощью **Статический** расписание с теми же границы для всех циклов.  Обратите внимание, что в следующем примере ноль используется как нижняя граница цикла, даже если во втором **k** был более естественны если расписание не было важно.  
  
```  
#pragma omp parallel  
{  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    a[i] = work1(i);  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    if(i>=k) a[i] += work2(i);  
}  
```  
  
 В остальных примерах предполагается доступ к памяти не доминантного рассмотрения, и, если не указано противн, что все потоки получают эквивалентные вычислительные ресурсы.  В этих случаях выбор расписания, a **для** зависит от конструкции полностью общего объема работы, выполняться между собой тесно предыдущим барьером и или неявный заключительный барьера или близко последующий барьера, если набор узлов a  `nowait` предложение.  Для каждого типа расписания, короткий примере показано, как этот тип расписания может быть самым лучшим выбором.  Краткое описание за каждым примере.  
  
 **Статический** расписание также соответствующие в самый простой случай, содержащий одно параллельной области  **для** конструкция, при каждой итерации, требующих то же самого объема работ.  
  
```  
#pragma omp parallel for schedule(static)  
for(i=0; i<n; i++) {  
  invariant_amount_of_work(i);  
}  
```  
  
 **Статический** расписание охарактеризовано свойствами, каждый поток возвращает приблизительно одному и тому же число итераций, как и любой другой поток, а каждый поток может независимо определить итерации, присвоенные него.  Таким образом, что рабочий и распределяет синхронизация при условии, что каждая итерация требует то же самого количества работы, все потоки должны завершить на примерно столько же самом времени.  
  
 Для рабочей группы  `p` потоки позволяют ceiling \(n\/p\) целое число q, который удовлетворяет n \= p\*q \- r с 0 \<\= r \< p.  Одна реализация  **Статический** для этого примера присвоитьTfо бы расписание q итерации к первому p\-1 потоки и q\-r итерации к последнему поток.  Другая реализация присвоитьTfа бы приемлемая *q* итерации к первому *p\-r* потоки и *q\-1* в оставшихся итерации *r* потоки.  Это показывает, почему программа не должна основываться на сведениях конкретной реализации.  
  
 **dynamic** расписание соответствующее в случае a  **для** конструкция при итерации, требующих varying или даже непрогнозируемое, ресурсы действий.  
  
```  
#pragma omp parallel for schedule(dynamic)  
  for(i=0; i<n; i++) {  
    unpredictable_amount_of_work(i);  
}  
```  
  
 **dynamic** расписание охарактеризовано свойством, ни один поток не ожидает барьере, длиннее он принимает другой поток для выполнения его на последней итерации.  Это требует, чтобы итераций присвоили поочередно в потоки, как только они становятся доступны, с синхронизацией для каждого присваивания.  Издержки синхронизации могут быть уменьшается, указав минимальный размер блока *k* больше 1, так что потоки будут присвоенны *k* одновременно до меньше *k* продолжить.  Это гарантирует, что ни один поток не ожидает барьере больше времени, чем он принимает другой поток для выполнения его окончательный блока \(по крайней мере\) *k* итерации.  
  
 **dynamic** расписание может быть полезно, если потоки получают различные вычислительные ресурсы, которое имеет много тот же эффект, что и ресурсы разных действий для каждой итерации.  Аналогично, динамическое расписание может быть полезно, если потоки поступают в **для** конструкция в различные моменты времени, однако в некоторых из этих вариантов  **направляется** расписание может быть предпочтительнее.  
  
 **направляется** расписание подходящее для варианта, в котором потоки могут прибывать на изменение времени на a  **для** конструкция при каждой итерации, требующих примерно столько же самого объема работ.  Это может произойти, если, например, **для** конструкция предшествует одним или несколькими разделами или  **для** конструкции with  `nowait` предложения.  
  
```  
#pragma omp parallel  
{  
  #pragma omp sections nowait  
  {  
    // ...  
  }  
  #pragma omp for schedule(guided)  
  for(i=0; i<n; i++) {  
    invariant_amount_of_work(i);  
  }  
}  
```  
  
 Как **dynamic**"  **направляется** расписание гарантирует, что ни один поток не ожидает барьере больше времени, чем он принимает другой поток для выполнения его последняя итерацию или выпускные экзамены k итерации, если размер блока k указывает.  Среди таких расписаний, **направляется** расписание охарактеризовано свойством, что оно требует минимальное число синхронизаций.  Для размера блока *k*типичная реализация, присвоит *q \= ceiling \(n\/p\)* итерации с первым доступным поток, набор *n* к наибольшему *n\-q* и *p\*k*повторение до всех итераций, а не присвоенны.  
  
 После выбора оптимального расписания не ясн по мере их для этих примеров **Исполняющая среда** расписание удобно для поэкспериментировать с различными расписаниями и размерами блока без изменения и выполните повторную компиляцию программы.  Также может быть полезным, если оптимальное расписание зависит \(каким\-либо образом прогнозируемый\) для входных данных, к которым применяется программа.  
  
 Чтобы просмотреть пример обмена между различными расписаниями, рассмотрите возможность совместного использования 1000 итераций среди 8 потоков.  Полагают, что инвариантный объем работ в каждой итерации и использовании, как единица измерения времени.  
  
 Если все потоки запускают в одно и то же время; **Статический** расписание будет конструкцию выполняться в единицах измерения, равных 125 без синхронизации.  Предположим, что один поток на 100 единиц последних в приезжать.  Затем оставшиеся 7 потоков, ожидающих 100 единиц в барьере, а время выполнения для всей конструкции увеличивается до 225.  
  
 Поскольку оба **dynamic** и  **направляется** расписания не гарантируют, что поток ожидает более чем одну единицу в барьере, отложенной поток, которые вызывают их времени выполнения для конструирования увеличить до 138 единиц, по возможности увеличенные задержками в синхронизации.  Если такие задержки не незначительны, то будет важно, чтобы число синхронизаций 1000 **dynamic** но только 41  **направляется**в предположении по умолчанию размер блока.  С размером блока 25 **dynamic** и  **направляется** оба завершатся в единицах измерения, равных 150, а также все задержки из требуемых синхронизаций, которые теперь номер, только 40 и 20 соответственно.