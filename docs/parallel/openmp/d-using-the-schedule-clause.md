---
title: Г. В соответствии с расписанием предложение | Документы Microsoft
ms.custom: ''
ms.date: 11/04/2016
ms.technology:
- cpp-parallel
ms.topic: conceptual
dev_langs:
- C++
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
author: mikeblome
ms.author: mblome
ms.workload:
- cplusplus
ms.openlocfilehash: 8987c4505adfde8534d57346cd6725231efa022f
ms.sourcegitcommit: 7019081488f68abdd5b2935a3b36e2a5e8c571f8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/07/2018
---
# <a name="d-using-the-schedule-clause"></a>Г. В соответствии с расписанием предложения
Параллельной области имеет по крайней мере один барьера со своей стороны и, возможно, дополнительных барьеры внутри него. В каждом барьера членами команды необходимо дождаться последнего потока поступления. Чтобы свести к минимуму время ожидания, должен быть предоставлен общей работы, чтобы все потоки образовать барьера, в то же время. Если некоторые, общих рабочих содержится в **для** конструкции `schedule` предложение может использоваться для этой цели.  
  
 Если имеются повторяющиеся ссылки на те же объекты, Выбор расписания для **для** конструкция может определяться в основном характеристики памяти системы, такие как наличие и размер кэша, а также является ли доступ к памяти время, универсальное или неоднородным доступом. Такие вопросы может сделать его более предпочтительной каждый поток постоянно ссылаться на тот же набор элементов в массиве, в ряде циклы, даже если некоторые потоки назначаются относительно меньше работы в некоторых циклов. Это можно сделать с помощью **статических** расписание с теми же границами все циклы for. В следующем примере обратите внимание, что ноль, даже если используется в качестве нижней границы в второй цикл **k** будет более естественным, если расписание не важно.  
  
```  
#pragma omp parallel  
{  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    a[i] = work1(i);  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    if(i>=k) a[i] += work2(i);  
}  
```  
  
 В остальных примерах предполагается, что память доступа не является главным рассмотрения и, если не указано иное, получение всех потоков сопоставимых вычислительные ресурсы. В таких случаях выбор расписания для **для** конструкция зависит от всех общих действий, которые должна выполняться от ближайшего предшествующего барьера и барьера подразумеваемых закрытия или ближайшего последующих барьера, при наличии `nowait` предложения. Для каждого вида расписание коротком примере показано, как такой тип расписания можно скорее всего, будут лучшим вариантом. Краткое описание каждого примера приводится.  
  
 **Статических** расписание также подходит в самом простом случае параллельной области содержит один **для** построения, и в каждой итерации требуется объем трудозатрат.  
  
```  
#pragma omp parallel for schedule(static)  
for(i=0; i<n; i++) {  
  invariant_amount_of_work(i);  
}  
```  
  
 **Статических** расписание характеризуется свойства, каждый поток получает приблизительно одинаковое количество итераций как любого другого потока, а каждый поток независимо определить итерации, назначенные его. Поэтому синхронизация не требуется для распределения работы и, исходя из предположения, что каждая итерация требует столько же работы, необходимо завершить все потоки в то же время.  
  
 Группа `p` потоков, позволяют *ceiling(n/p)* быть целым числом *q*, удовлетворяющий *n = p\*q - r* с *0 < = r < p* . Одна реализация **статических** расписания для этого примера будет назначен *q* итераций для первого *p-1* потоков, и *q-r* итераций для последнего потока.  Будет назначен другой допустимый реализации *q* итераций для первого *p-r* потоков, и *q-1* итераций для оставшихся *r*потоков. Это показывает, почему программа не следует полагаться на сведения о конкретной реализации.  
  
 **Динамическое** расписание подходит в случае **для** построения с итерациями, требующие различными или даже непредсказуемым объемы работы.  
  
```  
#pragma omp parallel for schedule(dynamic)  
  for(i=0; i<n; i++) {  
    unpredictable_amount_of_work(i);  
}  
```  
  
 **Динамическое** расписание характеризуется свойство, которое ни один поток не ожидает, пока в барьера больше времени, чем он принимает другой поток для выполнения его последней итерации. Для этого, итераций назначаться поочередно потоков, которые становятся доступными при синхронизации для каждого назначения. Затраты на синхронизацию может уменьшиться, указав размер фрагмента минимальное *k* больше, чем 1, чтобы потоки назначаются *k* за один раз до менее чем *k* остаются. Это гарантирует, что ни один поток ожидает на барьера дольше, чем требуется для выполнения его последний фрагмент (максимум) другой поток *k* итераций.  
  
 **Динамическое** расписания могут быть полезны при получать потоки varying количество вычислительных ресурсов, имеющий точно такой же эффект, как различные объемы работы для каждой итерации. Аналогичным образом, динамические расписание также может быть полезно, если потоки поступают на **для** конструкцию в различные моменты времени, хотя в некоторых из этих случаев **интерактивной** расписание может быть предпочтительнее.  
  
 **Интерактивной** расписание подходит для случая, в котором потоки могут достигать в различные моменты времени в **для** построения с каждой итерации требуется примерно столько же работы. Это может произойти, если, например, **для** конструкция предшествует один или несколько разделов или **для** конструкции `nowait` предложения.  
  
```  
#pragma omp parallel  
{  
  #pragma omp sections nowait  
  {  
    // ...  
  }  
  #pragma omp for schedule(guided)  
  for(i=0; i<n; i++) {  
    invariant_amount_of_work(i);  
  }  
}  
```  
  
 Как **динамическое**, **интерактивной** запланировать гарантирует, что ни один поток ожидает на барьера дольше, чем требуется для выполнения его последней итерации другой поток или конечное *k* итерации, если размер фрагмента данных *k* указано. Среди таких расписания **интерактивной** расписание характеризуется свойства требуется минимальное число синхронизаций. Для размера блока *k*, назначит типичная реализация *q = ceiling(n/p)* задать итерации к потоку первой доступной *n* в соответствии с большим из *n-q* и *p\*k*и повторите назначаются всех итераций.  
  
 Если выбрать оптимальное расписание не как открытый, так как для этих примерах **среды выполнения** расписание является удобным для экспериментов с различные расписания и фрагментами, размер без изменения и перекомпилируйте программу. Его также можно использовать при оптимальное расписание зависит (иным образом прогнозируемого) входных данных, к которому применяется программа.  
  
 Чтобы увидеть пример компромиссы между разные расписания, рассмотрите возможность совместного использования 1000 итераций по 8 потокам. Допустим, существует инвариантный объем работы в каждой итерации и использовать его в качестве единицы времени.  
  
 Если все потоки запускать одновременно, **статических** расписание вызовет конструкции для выполнения в единицах измерения 125 без синхронизации. Однако предположим, что один поток является вечером, поступающих на 100 единиц. Ожидание оставшихся семь потоков 100 единиц на барьера и время выполнения для всей конструкции увеличивается до 225.  
  
 Поскольку как **динамическое** и **интерактивной** расписания убедитесь, что ни один поток не ожидает более чем одной единицы в барьера, отложенной поток вызывает их времени выполнения для конструкции для увеличения только к 138 единицы измерения, задержка из синхронизации возможно увеличивается. Такие задержки, не незначительно, он становится важным, что число синхронизаций — 1000 для **динамическое** , но только 41 для **интерактивной**, при условии, что размер блока по умолчанию одного. Блоков размером 25 **динамическое** и **интерактивной** окончания в 150 единиц, а также все возможные задержки из требуется синхронизация, номер, который теперь только 40 до 20, соответственно.